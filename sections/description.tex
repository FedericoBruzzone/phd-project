Finding and working with the right abstractions for describing a problem or its solution is one of the central pillars of software engineering~\cite{Voelter12}



DSLs are programming languages with either a textual or graphical interface that, in contrast with general-purpose languages (GPLs), are designed to describe and solve problems in a specific domain. The main advantages of using a DSL over a GPL come from a communication and ease of use standpoint: many of the failures in software projects (large ones in particular) come from the difficulty to translate requirements into specifications and specifications into implementations, due to the lack of a common vocabulary. DSLs can make it easier to communicate with domain experts, providing both a description and a solution for the problem \cite{Fowler10}. It is also much easier and faster to train the developers on how to use a DSL rather than a GPL while at the same time ensuring the whole team is aligned on the same style and project-specific conventions, improving maintainability. On the other hand, DLSs developing skills are hardly transferable and difficult to design and develop.

All languages, both DLSs and GPLs, tend to be designed as monolotic pieces of software with very little opportunity for reuse. More and more interest has been given to reusability in language development during the recent years. The solution suggested by Schwerdfeger and Van Wyk is a modular approach to parse table definitions: each module represents a grammar fragment that can be precompiled and distributed as a standalone product \cite{Schwerdfeger09}. A complete parse table can than be obtained by combining grammar extensions into an host language. This approach leverages on the shared language concepts between different languages (such as loops, conditionals, assignments, etc.): these concepts always share the same semantics, but with a different syntax. Some of the frameworks embracing this approach are: JastAdd \cite{Hedin03}, xText \cite{Eclipse}, MontiCore \cite{Krahn10} and Neverlang \cite{Cazzola15c}, each addressing this problem in a unique way.

Modular DSL development frameworks are best suited to be used along with the feature-oriented programming paradigm (FOP). FOP is a programming paradigm for generation of software product lines (SPLs), a term referring to a set of techniques and engineering methods inspired by industrial production and marketing, in which product lining is the process of offering several related products for sale individually. SPLs, in the same way, deal with software variability of products that share the same code base: by splitting a product in the features it provides, a set of slightly different but related products can be generated by a composition-based mechanism applied on the constituent features of the SPL. The same concept applied to language development goes under the name of language product line (LPL). The LPL development can be faced either in a top-down or a bottom-up approach: the former builds the feature model first by performing a variability analysis during the design phase; the latter starts from a predefined base language, decomposes it in its parts and builds the feature model starting from there. For this project, I propose the use of a bottom-up approach, to achieve better maintainability and extendibility of the language families. Neverlang is a good case-study for this task because, differently from most of the other frameworks, which have been tested applying a top-down approach, such as Spoofax \cite{Visser10}, LansGems \cite{Wende09} and the aforementioned Monticore, already has its own tool for bottom-up LPL development in the form of AiDE \cite{Cazzola13g, Cazzola14e, Cazzola16i}. AiDE currently builds the language variability model on a syntactic level, evaluating the dependencies between the Neverlang modules based on the provided and required nonterminals of their grammar fragments. AiDE can then be used to produce a language definition by activating the desired features in the variability model.

The aim of this project would be to demonstrate that the best approach to LPL development is the \textit{multi-dimensional variability modeling}; in this approach the variability tree is replaced by a variability forest (or tree-set) in which each tree represents a different dimension of variability (or an implementation concern) \cite{Mendez-Acuna16}. On a high level, those dimensions can be sumarized into three groups.
\begin{itemize}
    \item \textit{Abstract syntax variability}: providing abstract syntax variability lets the user tune the complexity of the DSL changing amount of constructs that will be part of the language configuration. Including additional (not required) constructs to the language causes a needless increase in complexity. Constructs are usually grouped in features to facilitate their selection.
    \item \textit{Concrete syntax variability}: given the same abstract syntax, the choice of a particular concrete syntax is still relevant. Depending on context and type of user, for instance, a localized version of the DSL could be needed, or a graphical interface could be more suitable than a textual one.
    \item \textit{Semantic variability}: semantic variability refers to the capability of supporting different interpretations for the same construct. Some frameworks apply a role-based strategy, in which each role gives a different interpretation over the same abstract syntax.
\end{itemize}
In this project, the goal would be to produce a forest in which each tree represents either the abstract syntax, the concrete syntax or a semantic role. The concrete language feature implementation would be derived by applying a compositional algorithm over the set of selected features in the multi-dimensional variability model. In order for this to be doable, the framework must support a modularization approach in which each implementation concern is defined in a different language module. In every other case, multi-dimensional variability is just not possible.

A toolchain that supports this kind of development cycle is ASF+SDF+FeatureHouse, that uses ASF+SDF for modular language design and FeatureHouse as a languages variability management framework \cite{Liebig13}, but, to my knowledge, no framework or toolchain implements a bottom-up multi-dimensional variability model building algorithm based on semantic language features. I suggest that finding an euristic that reliably applies this strategy over a set of language artifacts would greatly increase the reliability and the productivity of the LPL: in the top-down approach, the feature model is built by the variability analysis performed by the human brain, which behaves on a functional (semantic) level; even though a variability model developed by a top-down approach is way harder to expand and maintain and for this reason used mainly for product lines with a few products and a limited set of features, it has the advantage of usually providing a coherent and human-readable structure. On the other hand, a syntax-based bottom-up approach scales better but has little to no knowledge of the underlying semantic features. A semantic-based variability model would be built with the goal of emulating the decision process performed by a human designer, achieving the best of both worlds.

Neverlang does not implement abstract syntax explicitly, but provides a module construct in which it is possible to define grammar fragments (that in Neverlang's syntax go under the \textit{reference syntax} section) and, in case, one or more semantic roles. Neither the reference syntax nor the roles are considered concrete unless they are imported by a \textit{slice}. This can be used (with surprising levels of flexibility) to greatly increase the degree of variability of the LPL: each module-defined reference syntax can both serve the use of abstract syntax and concrete syntax.

As a result, activating a feature in the abstract syntax tree would enable the possibility to activate all the compliant features in the concrete syntax tree (including the chosen abstract syntax, thing that would be impossible if the distinction between abstract and concrete syntaxes was clearly defined) and in turn the semantic roles in the relevant trees. The concrete language artifacts (slices) can be generated automatically by joining a concrete syntax definition with all the semantic roles compliant with that syntax. On a side note, the constraints of the feature model ensure every language configuration of the LPL is feasible.

To increase this flexibility even further, the mechanism would be extended to provide a translation mechanism between apparently incompatible syntax definitions sharing the same semantics: usually this result can be achieved simply by designing language artifacts with a finer grained level of modularity, an additional semantic role and/or a remapping in the order of the nonterminals in the grammar fragments, but some developers may find the possibility to translate a syntax into another more intuitive.

I propose a general roadmap to organize the resarch in order to achieve the project goals:
\begin{itemize}
    \item In the first six months I would expand my knowledge on LPLs and language development in general, I would perform a deeper study of all the most important approaches currently available in literature to elaborate on their pros and cons and lay a groundwork for my research work. Great attention would be given to the study of bottom-up and top-down approaches, in order to find their shared aspects. This process could lead to the drafting of a survey on language product lines.
    \item In the next year I would define a formal method to extrapolate features from the language artifacts. The challenge would be to rely on the artifact's semantics rather than its syntax elements. This method would be used to elaborate a general algorithm to build a multi-dimensional variability model based on the semantic language features. I would than proceed expanding the Neverlang framework to implement all the required features: first ad foremost a way to determine if two or more syntax definitions are compliant will be implemented and, later on, the focus will go towards other required utilities such as syntax translation or syntax inheritance. I would develop a system to automatically generate language slices from language artifacts. Each new feature should be subject to unit testing in order to ensure the reliability of the framework.
    \item In the next year I would implement, test and perfect the Neverlang version of the algorithm, studying its applicability in real world scenarios. This study would first be focused on DSL development from scratch and than to DSL expansion. The applicability of the method in both scenarios would be evaluated and compared to that of other LPL development frameworks. I would also try to improve the algorithm flexibility introducing a mixed approach, so that a top-down and a bottom-up approaches could be used in conjunction: the main disadvantage of the bottom-up approach is the lack of control over the variability model structure from the developer standpoint; a mixed approach would permit to perform a variability analysis during the design process to set part of the variability model structure while the rest of the features would be generated using the bottom-up approach. The fixed section of the variability model would not be subject to any changes upon updating the set language artifacts.
    \item In the last six months of the project I would proceed testing the applicability of the method by mixing and matching features from different languages, in order to evaluate the feasibility of a development cycle that does not include any production of language artifacts from scratch. I would also test the algorithm with at least one other framework to check how much the chosen paradigm and modularization strategies affect the semantic evaluation of the language artifacts.
\end{itemize}
